# -*- coding: utf-8 -*-
import os
import json
import asyncio
import aiohttp
import time
import re
from contextlib import asynccontextmanager

try:
    from google import genai
    from google.genai import types

    HAS_GOOGLE_GENAI = True
except Exception:
    HAS_GOOGLE_GENAI = False

# ==========================================
# 1. åŸºç¡€è·¯å¾„é…ç½®
# ==========================================
CONFIG_FILENAME = "3.ç»¼è¿°èƒŒæ™¯.json"
PACK_FILE_PATH = os.path.join("2.1åˆæˆpackæ–‡ä»¶", "pack.md")
DIR_OUTPUT_MODEL = "3.2ä¸‰ä¸‰ä¸‰æ¨¡å‹"

# ==========================================
# 2. åŠ¨æ€æç¤ºè¯æ¨¡æ¿
# ==========================================
PROMPT_TEMPLATE = """
æ–‡çŒ®ç­›é€‰ä¸‰ä¸‰ä¸‰æ¨¡å‹ï¼ˆField Mapping 3-3-3ï¼‰
ä½ æ˜¯èµ„æ·±æ–‡çŒ®ç»¼è¿°ç ”ç©¶é¡¾é—®ã€‚è¯·åŸºäºå•ä¸€å­é¢†åŸŸ Packï¼Œå®Œæˆâ€œ3äººç‰©-3è§‚ç‚¹-3æ–‡çŒ®-3ç¼ºå£â€çš„ç»“æ„åŒ–æ´å¯Ÿã€‚

ã€è¾“å…¥è®¾å®šã€‘
åˆ‡å…¥é¢†åŸŸï¼š{subfield_name}
ç›®æ ‡å­—æ•°ï¼š{target_words}å­—å·¦å³

ã€ç¡¬çº¦æŸã€‘
1. åªä½¿ç”¨ Pack å†…å®¹ï¼Œä¸å¾—å¼•å…¥å¤–éƒ¨æ–‡çŒ®æˆ–å¸¸è¯†è¡¥å…¨ã€‚
2. å¦‚è¯æ®ä¸è¶³ï¼Œæ˜ç¡®æ ‡æ³¨â€œPack è¯æ®ä¸è¶³â€ã€‚
3. åœ¨å¼•ç”¨çš„è¯­å¥ä¸­ä½¿ç”¨ï¼ˆAuthor,yearï¼‰[n]ï¼Œå…¶ä¸­[n]ä¸ºå‚è€ƒæ–‡çŒ®åˆ—è¡¨ä¸­çš„å¼•ç”¨æ¡ç›®çš„åºå·ã€‚
4. æ’ç‰ˆè¦æ±‚ï¼šä¸¥æ ¼ä½¿ç”¨ Markdown æ ¼å¼ï¼Œä¸»æ ‡é¢˜ä½¿ç”¨ ###ã€‚

ã€è¾“å‡ºç»“æ„ã€‘ï¼ˆä¸¥æ ¼æŒ‰åºï¼‰

### A. ä¸‰ç±»æ ¸å¿ƒå­¦æœ¯è§’è‰²ï¼ˆThe Whoï¼‰
- å¥ åŸºè€…ï¼ˆFounderï¼‰
- æŒ‘æˆ˜è€…ï¼ˆChallengerï¼‰
- é›†æˆè€…ï¼ˆSynthesizerï¼‰
æ¯ç±»ç»™å‡ºï¼šä»£è¡¨å­¦è€…/ä»£è¡¨ç ”ç©¶è·¯å¾„ã€æ ¸å¿ƒè´¡çŒ®ã€ä¸å¦å¤–ä¸¤ç±»çš„å…³ç³»ä¸€å¥è¯

### B. ä¸‰æ¡æ ¸å¿ƒè§‚ç‚¹è½´çº¿ï¼ˆThe Whatï¼‰
æ¯æ¡è½´çº¿å¿…é¡»åŒ…å«ï¼šè½´çº¿åç§°ï¼ˆå¦‚â€œæ•ˆç‡é€»è¾‘ vs å…¬å¹³é€»è¾‘â€ï¼‰ã€æ”¯æŒè¯æ®ç°‡ï¼ˆå¯¹åº”æ–‡çŒ®ï¼‰ã€äº‰è®®ç‚¹ä¸é€‚ç”¨è¾¹ç•Œ

### C. ä¸‰ç¯‡â€œé”šç‚¹æ–‡çŒ®â€ï¼ˆThe Evidenceï¼‰
é€‰æ‹© Pack ä¸­æœ€èƒ½æ”¯æ’‘è¯¥é¢†åŸŸç»“æ„çš„ 3 ç¯‡æ–‡çŒ®ï¼Œé€ç¯‡ç»™å‡ºï¼šä¸ºä»€ä¹ˆæ˜¯é”šç‚¹ã€å¯¹åç»­ç»¼è¿°å†™ä½œçš„ä»·å€¼

### D. ä¸‰ä¸ªç ”ç©¶ç¼ºå£å€™é€‰ï¼ˆThe Gapï¼‰
- Gap-1ï¼šè¾¹ç•Œæ¡ä»¶ç¼ºå£
- Gap-2ï¼šæœºåˆ¶è§£é‡Šç¼ºå£
- Gap-3ï¼šæƒ…å¢ƒ/å¯¹è±¡è¿ç§»ç¼ºå£
æ¯ä¸ªç¼ºå£éœ€å†™ï¼šæ—¢æœ‰ç ”ç©¶å·²è§£é‡Šä»€ä¹ˆã€å°šæœªè§£é‡Šä»€ä¹ˆã€ä¸ºä»€ä¹ˆå€¼å¾—ç ”ç©¶

### E. ç»¼è¿°æ¨è¿›å»ºè®®
ç”¨ä¸€æ®µè¯è¯´æ˜ï¼šè¯¥å­é¢†åŸŸåœ¨ Step 2 æœ€é€‚åˆé‡‡ç”¨å“ªç§å™è¿°æ¨¡å¼ï¼ˆoverall/top-down/bottom-upï¼‰ã€‚

### F. å‚è€ƒæ–‡çŒ®
ä»…åˆ—æ­£æ–‡å®é™…å¼•ç”¨æ¡ç›®ï¼ˆGBT7714-2015ï¼‰ã€‚
**æ’ç‰ˆå¼ºçº¦æŸ**ï¼šè¯·åŠ¡å¿…ä»¥ [1], [2], [3] çš„ç¼–å·å½¢å¼ç‹¬ç«‹æˆè¡Œè¾“å‡ºï¼Œæ¯ä¸€è¡Œåªå†™ä¸€æ¡å‚è€ƒæ–‡çŒ®ï¼Œç»å¯¹ä¸è¦æŠŠå¤šæ¡æ–‡çŒ®è¿åœ¨ä¸€è¡Œï¼
"""


# ==========================================
# 3. ä»£ç çº§å¼ºåˆ¶æ¸…æ´—ä¸æ’ç‰ˆå‡½æ•° (ä¸“å±ä¸‰ä¸‰ä¸‰æ¨¡å‹)
# ==========================================
def beautify_333_markdown(text):
    if not text:
        return text

    # 1. å¼ºåˆ¶çº æ­£å¤§æ ‡é¢˜æ ¼å¼ (é˜²æ­¢ AI å¿˜è®°åŠ  ### å¯¼è‡´ A. B. C. å˜æˆæ™®é€šæ–‡æœ¬)
    text = re.sub(r'(?m)^(?!\s*#)\s*([A-F]\.\s+.*?)$', r'### \1', text)

    # 2. å®šä½åˆ°â€œ### F. å‚è€ƒæ–‡çŒ®â€è¿™ä¸€èŠ‚è¿›è¡Œåˆ‡åˆ†
    match = re.search(r'(### F\.\s*å‚è€ƒæ–‡çŒ®.*?\n)(.*)', text, flags=re.IGNORECASE | re.DOTALL)

    if match:
        before_refs = text[:match.start(2)]
        refs_content = match.group(2)

        # 3. å¼ºè¡Œåˆ‡å‰²å‚è€ƒæ–‡çŒ®ï¼šæ‰¾åˆ°æ‰€æœ‰ "[1]", "[2]" å¹¶åœ¨å®ƒä»¬å‰é¢åŠ æ¢è¡Œç¬¦
        cleaned_refs = re.sub(r'\s*\[(\d+)\]\s*', r'\n[\1] ', refs_content)
        cleaned_refs = re.sub(r'\n{2,}', r'\n', cleaned_refs).strip()

        # é‡æ–°æ‹¼æ¥æ–‡æœ¬
        text = before_refs + cleaned_refs + '\n'

    # 4. æ ‡é¢˜å‰å¼ºåˆ¶åŠ ç©ºè¡Œï¼Œè®©ç‰ˆé¢æ›´é€æ°”
    text = re.sub(r'(?<!\n)\n(### [A-F]\.)', r'\n\n\1', text)

    return text.strip()


def log(msg, color="white"):
    timestamp = time.strftime("%H:%M:%S", time.localtime())
    colors = {"green": "\033[92m", "cyan": "\033[96m", "yellow": "\033[93m", "red": "\033[91m"}
    print(f"{colors.get(color, '')}[{timestamp}] {msg}\033[0m")


# ==========================================
# 4. API è°ƒç”¨å™¨ (å¤ç”¨ä¹‹å‰çš„é…ç½®é€»è¾‘)
# ==========================================
async def call_gemini(pack_content, prompt, config):
    gcfg = config.get("Google_Native_Config", {})
    keys = gcfg.get("api_keys", [])
    model_name = gcfg.get("model_name", "gemini-2.5-flash")

    if not keys or not HAS_GOOGLE_GENAI:
        raise RuntimeError("Google Gemini é…ç½®ç¼ºå¤±æˆ–æœªå®‰è£…SDKã€‚")

    for attempt, key in enumerate(keys, 1):
        try:
            client = genai.Client(api_key=key)
            cfg = types.GenerateContentConfig(temperature=0.3, system_instruction=prompt)
            log(f"   -> [Gemini] æ­£åœ¨æ„å»ºæ¨¡å‹æ¡†æ¶ (ä½¿ç”¨ Key {attempt}/{len(keys)})...", "cyan")

            resp = await asyncio.to_thread(
                client.models.generate_content,
                model=model_name,
                contents=[f"ä»¥ä¸‹æ˜¯å­é¢†åŸŸæ–‡çŒ® Pack çš„å†…å®¹ï¼š\n\n{pack_content}"],
                config=cfg
            )
            if resp.text: return resp.text
        except Exception as e:
            log(f"âš ï¸ Gemini Key {attempt} å¤±è´¥: {e}", "yellow")
            await asyncio.sleep(2)

    raise RuntimeError("æ‰€æœ‰ Gemini Key å‡è°ƒç”¨å¤±è´¥ã€‚")


async def call_openai(pack_content, prompt, config):
    ocfg = config.get("OpenAI_Protocol_Config", {})
    pool = ocfg.get("api_pool", [])
    proxy = config.get("Settings", {}).get("proxy_url", None)

    if not pool: raise RuntimeError("OpenAI èŠ‚ç‚¹æ± ä¸ºç©ºã€‚")

    timeout = aiohttp.ClientTimeout(total=180)
    async with aiohttp.ClientSession(timeout=timeout) as session:
        for attempt, node in enumerate(pool, 1):
            try:
                remark = node.get("remark", f"Node-{attempt}")
                url = f"{node['base_url'].rstrip('/')}{node['api_path']}"
                headers = {"Authorization": f"Bearer {node['api_key']}", "Content-Type": "application/json"}
                payload = {
                    "model": node["model_name"],
                    "messages": [
                        {"role": "system", "content": prompt},
                        {"role": "user", "content": f"ä»¥ä¸‹æ˜¯å­é¢†åŸŸæ–‡çŒ® Pack çš„å†…å®¹ï¼š\n\n{pack_content}"}
                    ],
                    "temperature": 0.3
                }

                log(f"   -> [OpenAI] æ­£åœ¨æ„å»ºæ¨¡å‹æ¡†æ¶ (è°ƒç”¨èŠ‚ç‚¹: {remark})...", "cyan")
                async with session.post(url, headers=headers, json=payload, proxy=proxy) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        return data["choices"][0]["message"]["content"]
                    else:
                        txt = await resp.text()
                        log(f"âš ï¸ OpenAI èŠ‚ç‚¹ {remark} å¤±è´¥ {resp.status}: {txt[:100]}", "yellow")
            except Exception as e:
                log(f"âš ï¸ OpenAI èŠ‚ç‚¹å¼‚å¸¸: {e}", "yellow")

            await asyncio.sleep(2)

    raise RuntimeError("æ‰€æœ‰ OpenAI èŠ‚ç‚¹å‡è°ƒç”¨å¤±è´¥ã€‚")


# ==========================================
# 5. ä¸»ç¨‹åºæµç¨‹
# ==========================================
async def main():
    print("===========================================")
    print("    æ–‡çŒ®ç­›é€‰ä¸‰ä¸‰ä¸‰æ¨¡å‹ç”Ÿæˆå™¨ (Field Mapping)  ")
    print("===========================================")

    os.makedirs(DIR_OUTPUT_MODEL, exist_ok=True)

    try:
        with open(CONFIG_FILENAME, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except FileNotFoundError:
        log(f"âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ '{CONFIG_FILENAME}'", "red")
        return

    if not os.path.exists(PACK_FILE_PATH):
        log(f"âŒ æ‰¾ä¸åˆ° Pack æ–‡ä»¶ '{PACK_FILE_PATH}'ï¼Œè¯·å…ˆè¿è¡Œåˆæˆè„šæœ¬ã€‚", "red")
        return

    with open(PACK_FILE_PATH, 'r', encoding='utf-8') as f:
        pack_content = f.read()

    log(f"âœ… æˆåŠŸè¯»å– Pack æ–‡ä»¶ (å­—ç¬¦æ•°: {len(pack_content)})", "green")

    print("\n-------------------------------------------")
    subfield_name = input("âœï¸  è¯·è¾“å…¥ã€åˆ‡å…¥é¢†åŸŸã€‘(ä¾‹å¦‚: ä¼ä¸šæ•°å­—åŒ–è½¬å‹ä¸åˆ›æ–°ç»©æ•ˆ): ").strip()
    target_words = input("âœï¸  è¯·è¾“å…¥ã€ç›®æ ‡å­—æ•°ã€‘(ä¾‹å¦‚: 2000): ").strip()

    if not subfield_name or not target_words:
        log("âŒ é¢†åŸŸæˆ–å­—æ•°ä¸èƒ½ä¸ºç©ºï¼Œç¨‹åºé€€å‡ºã€‚", "red")
        return

    final_prompt = PROMPT_TEMPLATE.format(
        subfield_name=subfield_name,
        target_words=target_words
    )

    provider = config.get("Settings", {}).get("interface_type", "openai_protocol")
    log("\nğŸš€ å¼€å§‹è°ƒåº¦ AI å¤§æ¨¡å‹ç”Ÿæˆä¸‰ä¸‰ä¸‰æ¨¡å‹æ´å¯Ÿ...", "cyan")

    try:
        if provider == "native_response":
            result_md = await call_gemini(pack_content, final_prompt, config)
        elif provider == "openai_protocol":
            result_md = await call_openai(pack_content, final_prompt, config)
        else:
            raise ValueError(f"æœªçŸ¥çš„åè®®ç±»å‹: {provider}")

        if not result_md:
            raise RuntimeError("AI è¿”å›äº†ç©ºç»“æœã€‚")

        # ã€æ ¸å¿ƒæ­¥éª¤ã€‘ä½¿ç”¨æ­£åˆ™å‡½æ•°è¿›è¡Œæ´—ç¨¿æ’ç‰ˆï¼Œç¡®ä¿ A~F æ ‡é¢˜åŠå‚è€ƒæ–‡çŒ®å®Œç¾è¾“å‡º
        result_md = beautify_333_markdown(result_md)

        safe_name = subfield_name.replace("/", "_").replace("\\", "_")
        output_path = os.path.join(DIR_OUTPUT_MODEL, f"Step2_{safe_name}_ä¸‰ä¸‰ä¸‰æ¨¡å‹.md")

        with open(output_path, "w", encoding="utf-8") as f:
            f.write(f"# æ–‡çŒ®ç­›é€‰ä¸‰ä¸‰ä¸‰æ¨¡å‹ï¼š{subfield_name}\n\n")
            f.write(result_md)

        log(f"\nğŸ‰ ç»“æ„åŒ–æ´å¯Ÿç”ŸæˆæˆåŠŸå¹¶å·²å®Œæˆä»£ç æ’ç‰ˆï¼\nğŸ“ æ–‡ä»¶å·²ä¿å­˜è‡³: {output_path}", "green")

    except Exception as e:
        log(f"\nâŒ ç”Ÿæˆå¤±è´¥: {e}", "red")


if __name__ == "__main__":
    import sys

    if sys.platform.startswith('win'):
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main())