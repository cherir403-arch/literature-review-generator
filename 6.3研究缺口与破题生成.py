# -*- coding: utf-8 -*-
import os
import sys
import io
import json
import asyncio
import aiohttp
import time
import re
from contextlib import asynccontextmanager

# ==========================================
# å¼ºåˆ¶å…¨å±€ UTF-8 ç¼–ç ç¯å¢ƒ
# ==========================================
os.environ["PYTHONIOENCODING"] = "utf-8"
try:
    if getattr(sys.stdout, "encoding", "") and sys.stdout.encoding.lower() != "utf-8":
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8", errors="replace")
except Exception:
    pass

try:
    from google import genai
    from google.genai import types
    HAS_GOOGLE_GENAI = True
except Exception:
    HAS_GOOGLE_GENAI = False

# ==========================================
# 1. åŸºç¡€é…ç½®ä¸è¶…æ—¶è®¾ç½®
# ==========================================
CONFIG_FILENAME = "6.ç ”ç©¶ç¼ºå£.json"
PACK_FILE_PATH = os.path.join("2.1åˆæˆpackæ–‡ä»¶", "pack.md")
DIR_OUTPUT_GAP = "5.ç ”ç©¶ç¼ºå£ä¸ç ´é¢˜"

CLIENT_TIMEOUT_SEC = 1800000
REQUEST_TIMEOUT_SEC = 1800000

# ==========================================
# 2. è®ºè¯å‹ç ”ç©¶ç¼ºå£æŒ–æ˜æç¤ºè¯ (æ¨¡å—åŒ–æ•´åˆç‰ˆ)
# ==========================================
PROMPT_TEMPLATE = """
# Role: é¡¶çº§æœŸåˆŠå®¡ç¨¿äººä¸è®ºæ–‡ç ´é¢˜ä¸“å®¶

ä»»åŠ¡ï¼šåŸºäºæä¾›çš„ã€åº•å±‚æ–‡çŒ®è¯æ® (Pack)ã€‘å’Œã€å¤šä»½æ·±åº¦åˆ†ææŠ¥å‘Šé›†ã€‘ç­‰èµ„æ–™ï¼Œç»“åˆä½œè€…æä¾›çš„ã€æ ¸å¿ƒæ´å¯Ÿã€‘ï¼ŒæŒ‰ç…§ä¸‰å¤§ç†è®ºå‘ç°åŸç†ï¼Œä¸€æ¬¡æ€§æ¨å¯¼å‡ºä¸‰ä¸ªå·®å¼‚åŒ–çš„ã€æ·±åˆ»ä¸”åˆ›æ–°çš„ç ”ç©¶ç¼ºå£ (Research Gap)ï¼Œä»¥è¯æ˜ã€ç›®æ ‡é€‰é¢˜ã€‘çš„åœ¨ç›®å‰çš„ç ”ç©¶ä¸­éå¸¸å…·å¤‡åˆ›æ–°æ€§ï¼Œå…·æœ‰å†™ä½œçš„ç†è®ºæ„ä¹‰ã€‚

## ä¸€ã€ åŸºç¡€çŸ¥è¯†ï¼ˆå¿…é¡»é˜…è¯»å’Œç†è§£å¹¶åº”ç”¨åœ¨åç»­ Action ä¸­ï¼‰

ï¼ˆä¸€ï¼‰ ç ”ç©¶ç¼ºå£ï¼ˆResearch Gapï¼‰åˆ†ç±»æŒ‡å—

ç ”ç©¶ Gap æŒ‡ç°æœ‰æ–‡çŒ®ä¸­å°šæœªè§£å†³ã€å°šæœªæ¢ç´¢ã€å­˜åœ¨äº‰è®®æˆ–ç†è§£ä¸é€å½»çš„é¢†åŸŸã€‚Gap æ˜¯è¿›è¡Œç ”ç©¶çš„ç†ç”±å’Œåˆæ³•æ€§æ¥æºã€‚

 1. è¯æ®ç©ºç™½/çŸ›ç›¾ç©ºç™½ (Evidence/Contradiction Gap)-æ¨è

 å®šä¹‰ï¼šé’ˆå¯¹åŒä¸€ä¸ªé—®é¢˜ï¼Œç°æœ‰çš„å®è¯ç ”ç©¶å¾—å‡ºäº†æˆªç„¶ä¸åŒã€ç”šè‡³å®Œå…¨ç›¸åçš„ç»“è®ºã€‚
 ä¾‹å­ï¼š
 Gap é™ˆè¿°ï¼šâ€œå…³äºè¿œç¨‹åŠå…¬å¯¹å‘˜å·¥åˆ›é€ åŠ›çš„å½±å“ï¼Œå­¦ç•Œå­˜åœ¨äº‰è®®ã€‚æ´¾åˆ« A è®¤ä¸ºè¿œç¨‹åŠå…¬æä¾›äº†å®‰é™ç¯å¢ƒï¼Œæå‡äº†åˆ›é€ åŠ›ï¼›æ´¾åˆ« B åˆ™è®¤ä¸ºç¼ºä¹é¢å¯¹é¢äº¤æµå‰Šå¼±äº†æ€æƒ³ç¢°æ’ã€‚ç›®å‰çš„æ–‡çŒ®æœªèƒ½è§£é‡Šè¿™ç§å·®å¼‚äº§ç”Ÿçš„æ¡ä»¶ã€‚â€
 åˆ‡å…¥ç‚¹ï¼šæˆ‘è®¤ä¸ºè¿™å–å†³äºâ€œä»»åŠ¡çš„æ€§è´¨â€ï¼ˆç‹¬ç«‹å‹ä»»åŠ¡ vs. åä½œå‹ä»»åŠ¡ï¼‰ã€‚

 2. çŸ¥è¯†ç©ºç™½ (Knowledge Gap)-æ¨è

 å®šä¹‰ï¼šé’ˆå¯¹æŸç§æ–°ç°è±¡ã€æ–°è¶‹åŠ¿ï¼Œå­¦æœ¯ç•Œè¿˜æ²¡æœ‰è¶³å¤Ÿçš„ç ”ç©¶æ•°æ®æˆ–ç†è®ºè§£é‡Šã€‚
 ä¾‹å­ï¼š
 Gap é™ˆè¿°ï¼šâ€œç°æœ‰çš„æ¶ˆè´¹è€…è¡Œä¸ºç†è®ºå¤§å¤šåŸºäº Web 2.0 çš„ç”µå•†æ¨¡å¼ã€‚ç„¶è€Œï¼Œéšç€ç”Ÿæˆå¼ AIï¼ˆå¦‚ ChatGPTï¼‰ä»‹å…¥è´­ç‰©å†³ç­–ï¼Œæ¶ˆè´¹è€…çš„ä¿¡ä»»æœºåˆ¶å’Œå†³ç­–è·¯å¾„å‘ç”Ÿäº†æ ¹æœ¬æ€§å˜åŒ–ï¼Œç›®å‰çš„æ–‡çŒ®å¯¹æ­¤å°šç¼ºä¹ç³»ç»Ÿçš„å®è¯æ¢ç´¢ã€‚â€

 3. æ–¹æ³•è®ºç©ºç™½ (Methodology Gap)-ä¸€èˆ¬ä¸é‡‡ç”¨ï¼Œä¸åˆ°ä¸‡ä¸å¾—å·²ä¸ä½¿ç”¨è¿™ä¸ª

 å®šä¹‰ï¼šå‰äººçš„ç ”ç©¶è™½ç„¶æœ‰ç»“è®ºï¼Œä½†ä½¿ç”¨çš„æ–¹æ³•å­˜åœ¨ç¼ºé™·ã€å±€é™ï¼Œæˆ–è€…è¿‡äºå•ä¸€ï¼Œå¯¼è‡´ç»“è®ºå¯èƒ½ä¸å‡†ç¡®æˆ–ä¸å…¨é¢ã€‚
 ä¾‹å­ï¼š
 Gap é™ˆè¿°ï¼šâ€œè™½ç„¶å·²æœ‰ç ”ç©¶è¯å®äº†ç¤¾äº¤åª’ä½“ä¼šå¯¼è‡´ç„¦è™‘ï¼Œä½†ç°æœ‰ç ”ç©¶å¤šé‡‡ç”¨æ¨ªæˆªé¢è®¾è®¡ï¼ˆCross-sectional designï¼‰ï¼Œæ— æ³•æ’é™¤åå‘å› æœå…³ç³»ï¼ˆå³ï¼šæ˜¯å› ä¸ºç„¦è™‘æ‰åˆ·æ‰‹æœºï¼Œè¿˜æ˜¯åˆ·æ‰‹æœºå¯¼è‡´ç„¦è™‘ï¼Ÿï¼‰ã€‚æœ¬ç ”ç©¶å°†é‡‡ç”¨çºµå‘è¿½è¸ªè®¾è®¡æ¥å˜æ¸…è¿™ä¸€å› æœé“¾æ¡ã€‚â€

 4. ç†è®ºåº”ç”¨ç©ºç™½ (Theoretical Application Gap)-æ¨è

 å®šä¹‰ï¼šç°æœ‰çš„ç†è®ºæ¡†æ¶è§£é‡ŠåŠ›ä¸è¶³ï¼Œæˆ–è€…æˆ‘ä»¬å¯ä»¥æŠŠ A é¢†åŸŸçš„æˆç†Ÿç†è®ºï¼Œå€Ÿç”¨åˆ° B é¢†åŸŸæ¥è§£é‡Šæ–°é—®é¢˜ã€‚
 ä¾‹å­ï¼š
 Gap é™ˆè¿°ï¼šâ€œä»¥å¾€å¯¹å‘˜å·¥ç¦»èŒå€¾å‘çš„ç ”ç©¶ä¸»è¦åŸºäºâ€˜ç¤¾ä¼šäº¤æ¢ç†è®ºâ€™ï¼ˆåˆ©ç›Šäº¤æ¢ï¼‰ã€‚ç„¶è€Œï¼Œå¯¹äºä»¥â€˜è‡ªæˆ‘å®ç°â€™ä¸ºæ ¸å¿ƒçš„æ–°ç”Ÿä»£å‘˜å·¥ï¼Œè¿™ä¸€ç†è®ºè§£é‡ŠåŠ›ä¸‹é™ã€‚æœ¬ç ”ç©¶å°è¯•å¼•å…¥â€˜å·¥ä½œé‡å¡‘ç†è®ºâ€™ï¼ˆJob Crafting Theoryï¼‰ï¼Œä»å¿ƒç†éœ€æ±‚æ»¡è¶³çš„æ–°è§†è§’æ¥è§£é‡Šè¿™ä¸€ç°è±¡ã€‚â€

 5. æƒ…å¢ƒ/å¯¹è±¡ç©ºç™½ (Context/Population Gap)-ä¸€èˆ¬

 å®šä¹‰ï¼šæŸä¸ªç†è®ºåœ¨ A ç¯å¢ƒï¼ˆå¦‚è¥¿æ–¹å›½å®¶ã€å¤§ä¼ä¸šï¼‰è¢«éªŒè¯äº†ï¼Œä½†åœ¨ B ç¯å¢ƒï¼ˆå¦‚ä¸­å›½ã€ä¸­å°ä¼ä¸šï¼‰æ˜¯å¦é€‚ç”¨ï¼Ÿ
 ä¾‹å­ï¼š
 å¼± Gapï¼šâ€œæ²¡äººç ”ç©¶è¿‡ä¸­å›½å››å·åœ°åŒºçš„æ¡ˆä¾‹ã€‚â€ï¼ˆReviewer ä¼šé—®ï¼šå››å·æœ‰ä»€ä¹ˆç‰¹åˆ«çš„å—ï¼Ÿå¦‚æœæ²¡æœ‰ï¼Œè¿™ä¸ªç ”ç©¶æ²¡æ„ä¹‰ã€‚ï¼‰
 å¼º Gapï¼šâ€œç°æœ‰çš„ä¼ä¸šç¤¾ä¼šè´£ä»»ï¼ˆCSRï¼‰æ¨¡å‹ä¸»è¦å»ºç«‹åœ¨è¥¿æ–¹åˆ¶åº¦èƒŒæ™¯ä¸‹ã€‚ç„¶è€Œï¼Œåœ¨ä¸­å›½â€˜å…³ç³»æœ¬ä½â€™å’Œæ”¿åºœä¸»å¯¼çš„ç‰¹æ®Šå•†ä¸šç¯å¢ƒä¸­ï¼Œä¼ä¸šå±¥è¡Œ CSR çš„åŠ¨æœºå¯èƒ½æˆªç„¶ä¸åŒã€‚å› æ­¤ï¼Œæœ‰å¿…è¦æ£€éªŒè¥¿æ–¹æ¨¡å‹åœ¨ä¸­å›½æƒ…å¢ƒä¸‹çš„é€‚ç”¨æ€§ã€‚â€

 6. å®è·µ-åº”ç”¨ç©ºç™½ (Practice-Application Gap)-ä¸€èˆ¬

 å®šä¹‰ï¼šå­¦æœ¯ç ”ç©¶çš„å»ºè®®ä¸å®é™…ä»ä¸šè€…çš„è¡Œä¸ºä¹‹é—´å­˜åœ¨è„±èŠ‚ã€‚
 ä¾‹å­ï¼š
 Gap é™ˆè¿°ï¼šâ€œå°½ç®¡å¤§é‡æ–‡çŒ®å»ºè®®åŒ»ç”Ÿåœ¨å‘ŠçŸ¥åæ¶ˆæ¯æ—¶åº”éµå¾ªâ€˜SPIKES æ¨¡å‹â€™ï¼Œä½†ä¸´åºŠè§‚å¯Ÿå‘ç°ï¼Œæ€¥è¯Šç§‘åŒ»ç”Ÿæå°‘ä½¿ç”¨è¯¥æ¨¡å‹ã€‚ç°æœ‰çš„ç ”ç©¶å¿½ç•¥äº†â€˜é«˜æ—¶é—´å‹åŠ›â€™è¿™ä¸€ç°å®çº¦æŸå¯¹ç†è®ºåº”ç”¨çš„å½±å“ï¼Œæœ¬ç ”ç©¶æ—¨åœ¨æ¢ç´¢é€‚åˆæ€¥è¯Šç¯å¢ƒçš„æ”¹è‰¯æ²Ÿé€šæ¨¡å‹ã€‚â€

ï¼ˆäºŒï¼‰ç ”ç©¶ç¼ºå£å‘ç°çš„ä¸‰å¤§åŸç†
åœ¨è¿›è¡Œæ¨å¯¼å‰ï¼Œè¯·åŠ¡å¿…ç†è§£å¹¶åº”ç”¨ä»¥ä¸‹åŸç†ï¼š
1. é€é•œåŸç† (Lens Principle)ï¼šèšç„¦æ–‡çŒ®ç»“è®ºçš„çŸ›ç›¾ä¸ä¸ä¸€è‡´æ€§ï¼Œå¯»æ‰¾è¢«å¿½è§†çš„è°ƒèŠ‚å˜é‡æˆ–è¾¹ç•Œæ¡ä»¶ã€‚
2. æ—¶æ»åŸç† (Time-Lag Principle)ï¼šè¯†åˆ«ç»å…¸ç†è®ºåœ¨é¢å¯¹æ–°æ”¿ç­–ã€æ–°æƒ…å¢ƒæˆ–æ–°æœºåˆ¶ä¸‹çš„è§£é‡ŠåŠ›å¤±æ•ˆã€‚
3. å…‰å½±åŸç† (Light-Shadow Principle)ï¼šæ‰¹åˆ¤ä¸»æµèŒƒå¼æ‰€ç³»ç»Ÿæ€§é®è”½çš„è§†è§’ã€‚

ï¼ˆä¸‰ï¼‰æœ‰æ— Gapå†™ä½œç¤ºä¾‹ï¼š
- æ²¡æœ‰ Gapæè¿°ï¼š æˆ‘æƒ³ç ”ç©¶â€œè¿åŠ¨å¯¹å‡è‚¥çš„å½±å“â€ã€‚ï¼ˆè¿™å·²ç»è¢«ç ”ç©¶çƒ‚äº†ï¼Œæ²¡æœ‰æ„ä¹‰ï¼‰ã€‚
- æœ‰ Gap æè¿°ï¼š ç°æœ‰ç ”ç©¶å¤§é‡è¯å®äº†æœ‰æ°§è¿åŠ¨å¯¹å‡è‚¥çš„æ•ˆæœï¼ˆç»¼ï¼‰ï¼Œä½†å¤§å¤šé›†ä¸­åœ¨é•¿æœŸåšæŒè¿åŠ¨çš„äººç¾¤ï¼ˆè¯„ï¼‰ã€‚ç„¶è€Œï¼Œå¯¹äºé‚£äº›â€œä¸‰å¤©æ‰“é±¼ä¸¤å¤©æ™’ç½‘â€çš„é—´æ­‡æ€§è¿åŠ¨è€…ï¼Œå…¶ä»£è°¢æœºåˆ¶æœ‰ä½•ä¸åŒï¼Œç›®å‰å°šç¼ºä¹è¶³å¤Ÿçš„å®è¯è¯æ®ï¼ˆè¿™æ˜¯Gapï¼‰ã€‚ å› æ­¤ï¼Œæœ¬ç ”ç©¶æ—¨åœ¨â€¦â€¦

## äºŒã€ è¾“å…¥è®¾å®š
- ç›®æ ‡é€‰é¢˜ï¼š{topic}
- ä½œè€…æ´å¯Ÿï¼š{user_suggestion}
  (æ³¨ï¼šè¿™æ˜¯ç ´é¢˜çš„æ ¸å¿ƒæ”¯ç‚¹ï¼Œè¯·å°†å…¶æ¤å…¥ä¸‰ä¸ªæ–¹æ¡ˆçš„è®ºè¯é€»è¾‘ä¸­ï¼Œå®ç°ç†è®ºä¸æœºåˆ¶çš„è´¯é€šã€‚)
- ç›®æ ‡å­—æ•°ï¼šæ¯ä¸ªæ–¹æ¡ˆçº¦ {target_words} å­—ã€‚

## ä¸‰ã€ ä¸Šä¸‹æ–‡ææ–™ (Context)
1. **åº•å±‚æ–‡çŒ®è¯æ®åº“ (Pack)**ï¼šæä¾›é¢—ç²’åº¦å®è¯è¯æ®ï¼ˆå‘ä¸‹æ‰æ ¹ï¼‰ã€‚
2. **æ·±åº¦åˆ†ææŠ¥å‘Šé›†**ï¼šåŒ…å«äº†ä½œè€…å‰æœŸå¯¹ç›¸å…³æ¦‚å¿µã€æ”¿ç­–æˆ–ç°æœ‰ç»¼è¿°çš„é«˜ç»´è§£æ„ï¼ˆå‘ä¸Šç”Ÿé•¿ï¼‰ã€‚è¯·ä»¥æ­¤ä½œä¸ºç†è®ºæ¨æ¼”çš„åŸºçŸ³ï¼Œå°†è¿™äº›æ¦‚å¿µæˆ–æ”¿ç­–çš„å±æ€§èåˆåˆ°ç¼ºå£çš„æ¨å¯¼ä¸­ã€‚

## å››ã€ æ‰§è¡Œé€»è¾‘ï¼šå¹¶è¡Œäº§å‡ºä¸‰å¥—æ–¹æ¡ˆ
è¯·å–æ¶ˆæš‚åœï¼Œç›´æ¥è¾“å‡ºä»¥ä¸‹ä¸‰ä¸ªæ–¹æ¡ˆï¼Œæ¯ä¸ªæ–¹æ¡ˆå‡é¡»ä¸¥æ ¼éµå®ˆâ€œä¸‰æ˜æ²»æ¨¡å‹â€æ’°å†™ï¼š

### æ–¹æ¡ˆ Aï¼šåŸºäºã€é€é•œåŸç†ã€‘çš„é€»è¾‘æ¨æ¼”
- é€»è¾‘ï¼šé€šè¿‡ Pack å¯»æ‰¾è¯æ®å†²çªï¼Œåˆ©ç”¨ã€æ·±åº¦åˆ†ææŠ¥å‘Šã€‘ä¸­çš„å˜é‡å±æ€§ä¸ã€ä½œè€…æ´å¯Ÿã€‘ä½œä¸ºâ€œé€é•œâ€æ¥è§£é‡Šã€‚
- æ’°å†™ï¼š[è‚¯å®šç°çŠ¶(å¼•è¿°æŠ¥å‘Šé›†å®šè°ƒ)] -> [æŒ‡å‡ºç¼ºå£(å¼•ç”¨Packé¶å­)] -> [å æ®ç¼ºå£(å¼•å‡ºé€‰é¢˜)]
- ç±»å‹ï¼šæ ‡å‡ºè¿™ä¸ª Gap å±äºç ”ç©¶ç¼ºå£åˆ†ç±»ä¸­çš„å“ªä¸€ç±»ï¼Œå¹¶ç®€è¦è¯´æ˜åŸå› 

### æ–¹æ¡ˆ Bï¼šåŸºäºã€æ—¶æ»åŸç†ã€‘çš„é€»è¾‘æ¨æ¼”
- é€»è¾‘ï¼šè®ºè¯ç°æœ‰ç†è®ºåœ¨å¤„ç†ã€ç›®æ ‡é€‰é¢˜ã€‘æ¶‰åŠçš„ç°å®å˜åŒ–ï¼ˆåŸºäºæ”¿ç­–æˆ–æ¦‚å¿µæŠ¥å‘Šï¼‰æ—¶å­˜åœ¨æ»åï¼Œæ€¥éœ€æƒ…å¢ƒåŒ–è¡¥å……ã€‚
- æ’°å†™ï¼š[è‚¯å®šç°çŠ¶(å¼•è¿°æŠ¥å‘Šé›†å®šè°ƒ)] -> [æŒ‡å‡ºç¼ºå£(å¼•ç”¨Packé¶å­)] -> [å æ®ç¼ºå£(å¼•å‡ºé€‰é¢˜)]
- ç±»å‹ï¼šæ ‡å‡ºè¿™ä¸ª Gap å±äºç ”ç©¶ç¼ºå£åˆ†ç±»ä¸­çš„å“ªä¸€ç±»ï¼Œå¹¶ç®€è¦è¯´æ˜åŸå› 

### æ–¹æ¡ˆ Cï¼šåŸºäºã€å…‰å½±åŸç†ã€‘çš„é€»è¾‘æ¨æ¼”
- é€»è¾‘ï¼šåˆ©ç”¨ã€ä½œè€…æ´å¯Ÿã€‘æ‰¹åˆ¤ç°æœ‰ç ”ç©¶èŒƒå¼çš„ç›²åŒºï¼Œè¯æ˜ä½ è¡¥å……çš„å˜é‡æˆ–è§†è§’æ˜¯å…‰å½±èƒŒåçš„å…³é”®çœŸç›¸ã€‚
- æ’°å†™ï¼š[è‚¯å®šç°çŠ¶(å¼•è¿°æŠ¥å‘Šé›†å®šè°ƒ)] -> [æŒ‡å‡ºç¼ºå£(å¼•ç”¨Packé¶å­)] -> [å æ®ç¼ºå£(å¼•å‡ºé€‰é¢˜)]
- ç±»å‹ï¼šæ ‡å‡ºè¿™ä¸ª Gap å±äºç ”ç©¶ç¼ºå£åˆ†ç±»ä¸­çš„å“ªä¸€ç±»ï¼Œå¹¶ç®€è¦è¯´æ˜åŸå› 

## äº”ã€ çº¦æŸ
1. å¼•ç”¨æ ¼å¼ï¼š(Author, year) [n]ã€‚
2. å‚è€ƒæ–‡çŒ®ï¼šåœ¨æ–‡æœ«ç»Ÿä¸€æŒ‰ç…§ GBT7714-2015 æ ¼å¼åˆ—å‡ºï¼Œæ¯è¡Œä»…é™ä¸€æ¡æ–‡çŒ®ï¼Œä¸¥ç¦åˆå¹¶ã€‚
""".strip()

# ==========================================
# 3. è¾…åŠ©å‡½æ•°ï¼šæ‰«æã€æ’ç‰ˆä¸æ—¥å¿—
# ==========================================
def scan_analysis_files():
    """æ‰«æç›®å½•ä¸‹çš„æ¨¡å—åŒ–åˆ†ææŠ¥å‘Šï¼Œæ”¯æŒ 3~9 å¼€å¤´çš„æ–‡ä»¶å¤¹"""
    analysis_files = []
    valid_dirs = [d for d in os.listdir('.') if os.path.isdir(d) and re.match(r'^[3-9]\.', d)]
    for d in valid_dirs:
        for f in os.listdir(d):
            if f.endswith('.md'):
                analysis_files.append({"folder": d, "filename": f, "path": os.path.join(d, f)})
    return analysis_files

def beautify_gap_md(text):
    if not text:
        return text
    text = re.sub(r'(?m)^(?!\s*#)\s*(Phase \d:.*?)$', r'### \1', text)
    if "å‚è€ƒæ–‡çŒ®" in text:
        parts = re.split(r'(###.*?å‚è€ƒæ–‡çŒ®.*?\n)', text, flags=re.IGNORECASE)
        if len(parts) > 2:
            ref_content = parts[-1]
            ref_content = re.sub(r'\s*\[(\d+)\]\s*', r'\n[\1] ', ref_content)
            text = "".join(parts[:-1]) + ref_content.strip() + "\n"
    return text.strip()

def log(msg, color="white"):
    colors = {"green": "\033[92m", "cyan": "\033[96m", "yellow": "\033[93m", "red": "\033[91m"}
    print(f"{colors.get(color, '')}[{time.strftime('%H:%M:%S')}] {msg}\033[0m")

async def show_heartbeat(start_time, stop_event):
    spinner = ['â ‹', 'â ™', 'â ¹', 'â ¸', 'â ¼', 'â ´', 'â ¦', 'â §', 'â ‡', 'â ']
    i = 0
    while not stop_event.is_set():
        elapsed = int(time.time() - start_time)
        mins, secs = divmod(elapsed, 60)
        frame = spinner[i % len(spinner)]
        sys.stdout.write(
            f"\r\033[93m[{time.strftime('%H:%M:%S')}] {frame} ğŸ§  AI æ­£åœ¨èåˆå¤šæ¨¡å—æŠ¥å‘Šæ¨æ¼” GAP æ–¹æ¡ˆ... å·²è€—æ—¶: {mins:02d}åˆ†{secs:02d}ç§’\033[0m"
        )
        sys.stdout.flush()
        i += 1
        await asyncio.sleep(0.1)
    sys.stdout.write("\r" + " " * 110 + "\r")
    sys.stdout.flush()

# ==========================================
# 4. è½®è¯¢æ±  + ç†”æ–­ä¸Šä¸‹æ–‡ï¼ˆç¨³å¥æ€§æ ¸å¿ƒï¼‰
# ==========================================
class NoAvailableAPI(Exception):
    pass

class RoundRobinPool:
    """
    è½®è¯¢æ± ï¼šæ”¯æŒâ€œæœ¬è½®ç¦ç”¨(banned_set)â€ä¸ parked ç¼“å†²ã€‚
    borrow() ä¼šè‡ªåŠ¨è·³è¿‡è¢«ç¦ç”¨é¡¹ï¼Œå¹¶åœ¨ finally æ—¶å›æ”¶ã€‚
    """
    def __init__(self, items, id_fn):
        self.id_fn = id_fn
        self.total = len(items)
        self.q = asyncio.Queue()
        for it in items:
            self.q.put_nowait(it)
        self.parked = []
        self.in_use = 0
        self.round_id = 0

    def begin_round(self, round_id: int):
        self.round_id = round_id
        if self.parked:
            for it in self.parked:
                self.q.put_nowait(it)
            self.parked = []

    def end_round(self):
        if self.parked:
            for it in self.parked:
                self.q.put_nowait(it)
            self.parked = []

    def _all_banned_now(self, banned_set):
        return (len(banned_set) >= self.total) and (self.in_use == 0) and (self.q.qsize() == 0)

    @asynccontextmanager
    async def borrow(self, banned_set: set, round_id: int):
        if self.total <= 0:
            raise NoAvailableAPI("æ± ä¸ºç©º")
        if self._all_banned_now(banned_set):
            raise NoAvailableAPI("æœ¬è½®æ‰€æœ‰ API å·²è¢«ç¦ç”¨")

        item = None
        while True:
            if self._all_banned_now(banned_set):
                raise NoAvailableAPI("æœ¬è½®æ‰€æœ‰ API å·²è¢«ç¦ç”¨")
            try:
                item = await asyncio.wait_for(self.q.get(), timeout=2.0)
            except asyncio.TimeoutError:
                continue

            item_id = self.id_fn(item)
            if item_id in banned_set:
                self.parked.append(item)
                item = None
                continue
            break

        self.in_use += 1
        try:
            yield item
        finally:
            self.in_use -= 1
            item_id = self.id_fn(item)
            if item_id in banned_set:
                self.parked.append(item)
            else:
                self.q.put_nowait(item)

class RoundContext:
    def __init__(self, round_id: int):
        self.round_id = round_id
        self.gemini_banned = set()
        self.openai_banned = set()

def mask_key(s: str) -> str:
    s = str(s or "")
    return "***" + s[-6:] if len(s) > 6 else "***"

# ==========================================
# 5. ç¨³å¥ AI è°ƒç”¨å™¨ï¼ˆæ›¿æ¢åŸ call_aiï¼‰
# ==========================================
class AIClientRobust:
    def __init__(self, config: dict):
        self.config = config
        self.settings = config.get("Settings", {}) or {}
        self.interface_type = self.settings.get("interface_type", "openai_protocol")
        self.proxy = self.settings.get("proxy_url", None)

        if self.proxy:
            os.environ["http_proxy"] = self.proxy
            os.environ["https_proxy"] = self.proxy

        # Gemini é…ç½®
        gcfg = config.get("Google_Native_Config", {}) or {}
        self.google_model = gcfg.get("model_name", "gemini-2.5-flash")
        self.google_max_attempts = max(1, int(gcfg.get("max_attempts", 3)))
        self.google_keys = gcfg.get("api_keys", []) or []
        self.gemini_pool = RoundRobinPool(self.google_keys, id_fn=lambda k: str(k)) if self.google_keys else None

        # OpenAI Protocol é…ç½®
        ocfg = config.get("OpenAI_Protocol_Config", {}) or {}
        self.openai_max_attempts = max(1, int(ocfg.get("max_attempts", 3)))
        self.openai_nodes = ocfg.get("api_pool", []) or []
        self.openai_pool = RoundRobinPool(self.openai_nodes, id_fn=self._node_id) if self.openai_nodes else None

        # è¶…æ—¶ï¼ˆä¿æŒä½ åŸæ¥çš„â€œè¶…å¤§è¶…æ—¶â€è®¾å®šï¼‰
        self.timeout_settings = aiohttp.ClientTimeout(total=CLIENT_TIMEOUT_SEC, sock_read=REQUEST_TIMEOUT_SEC)

    def begin_round(self, round_ctx: RoundContext):
        if self.gemini_pool:
            self.gemini_pool.begin_round(round_ctx.round_id)
        if self.openai_pool:
            self.openai_pool.begin_round(round_ctx.round_id)

    def end_round(self):
        if self.gemini_pool:
            self.gemini_pool.end_round()
        if self.openai_pool:
            self.openai_pool.end_round()

    def _node_id(self, node: dict) -> str:
        return node.get("remark", f"{node.get('base_url')}|{node.get('model_name')}")

    async def call(self, combined_content: str, prompt: str, round_ctx: RoundContext) -> str:
        provider = self.interface_type

        if provider == "native_response":
            if not HAS_GOOGLE_GENAI:
                raise RuntimeError("æœªå®‰è£… google-genaiï¼Œæ— æ³•ä½¿ç”¨ native_response")
            if not self.gemini_pool:
                raise RuntimeError("Google_Native_Config.api_keys ä¸ºç©ºï¼Œæ— æ³•è°ƒç”¨ Gemini")
            return await self._call_gemini(combined_content, prompt, round_ctx)

        if provider == "openai_protocol":
            if not self.openai_pool:
                raise RuntimeError("OpenAI_Protocol_Config.api_pool ä¸ºç©ºï¼Œæ— æ³•è°ƒç”¨ OpenAI Protocol")
            return await self._call_openai_protocol(combined_content, prompt, round_ctx)

        raise ValueError("æœªçŸ¥çš„ interface_type")

    async def _call_gemini(self, combined_content: str, prompt: str, round_ctx: RoundContext) -> str:
        """
        Geminiï¼šè½®è¯¢ key + ç†”æ–­ + é‡è¯•
        - å¯¹ 429/RESOURCE_EXHAUSTEDï¼šæœ¬è½®ç¦ç”¨è¯¥ key
        - å…¶å®ƒå¼‚å¸¸ï¼šç»§ç»­æ¢ key / é‡è¯•
        """
        last_err = None

        for attempt in range(1, self.google_max_attempts + 1):
            async with self.gemini_pool.borrow(round_ctx.gemini_banned, round_ctx.round_id) as api_key:
                key_short = mask_key(api_key)
                try:
                    client = genai.Client(api_key=api_key, http_options={'timeout': REQUEST_TIMEOUT_SEC})
                    cfg = types.GenerateContentConfig(temperature=0.3, system_instruction=prompt)

                    log(f"-> [Gemini] Attempt {attempt}/{self.google_max_attempts} | Key {key_short} | model={self.google_model}", "cyan")
                    resp = await asyncio.to_thread(
                        client.models.generate_content,
                        model=self.google_model,
                        contents=[combined_content],
                        config=cfg
                    )
                    text = getattr(resp, "text", None)
                    if text:
                        return text
                    raise RuntimeError("Gemini è¿”å›ä¸ºç©º")

                except Exception as e:
                    last_err = e
                    msg = str(e).lower()

                    # å¸¸è§é™æµ/é…é¢è€—å°½
                    if ("429" in msg) or ("resource_exhausted" in msg) or ("exhausted" in msg) or ("quota" in msg):
                        round_ctx.gemini_banned.add(str(api_key))
                        log(f"ğŸš« [Gemini] è§¦å‘é™æµ/é…é¢ï¼Œæœ¬è½®ç¦ç”¨ Key {key_short} | {e}", "yellow")
                        await asyncio.sleep(min(8, 2 + attempt))
                        continue

                    # å…¶ä»–é”™è¯¯ï¼šè®°å½•å¹¶çŸ­é€€é¿åç»§ç»­ï¼ˆä¼šæ¢ keyï¼‰
                    log(f"âš ï¸ [Gemini] å¼‚å¸¸ï¼ˆå°†é‡è¯•/æ¢Keyï¼‰: {e}", "yellow")
                    await asyncio.sleep(min(6, 1 + attempt))
                    continue

        raise RuntimeError(f"Gemini å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä»å¤±è´¥ï¼š{last_err}")

    async def _call_openai_protocol(self, combined_content: str, prompt: str, round_ctx: RoundContext) -> str:
        """
        OpenAI Protocolï¼šè½®è¯¢ node + ç†”æ–­ + é‡è¯•
        - å¯¹ 429/503/504ï¼šæœ¬è½®ç¦ç”¨è¯¥èŠ‚ç‚¹ï¼ˆæ›´æ¿€è¿›ï¼Œé¿å…å¡æ­»ï¼‰
        - å¯¹ é 200ï¼šè¯»å– text ä½œä¸ºé”™è¯¯ä¿¡æ¯ï¼›å¿…è¦æ—¶ç¦ç”¨
        - å¯¹ç½‘ç»œå¼‚å¸¸ï¼šç¦ç”¨å¹¶æ¢èŠ‚ç‚¹
        """
        last_err = None

        async with aiohttp.ClientSession(timeout=self.timeout_settings) as session:
            for attempt in range(1, self.openai_max_attempts + 1):
                async with self.openai_pool.borrow(round_ctx.openai_banned, round_ctx.round_id) as node:
                    node_id = self._node_id(node)
                    remark = node.get("remark", "Unknown")
                    url = f"{node['base_url'].rstrip('/')}{node['api_path']}"
                    headers = {"Authorization": f"Bearer {node['api_key']}", "Content-Type": "application/json"}

                    payload = {
                        "model": node["model_name"],
                        "messages": [
                            {"role": "system", "content": prompt},
                            {"role": "user", "content": combined_content}
                        ],
                        "temperature": 0.3
                    }

                    try:
                        log(f"-> [OpenAI] Attempt {attempt}/{self.openai_max_attempts} | Node {remark} | model={node.get('model_name')}", "cyan")
                        async with session.post(url, headers=headers, json=payload, proxy=self.proxy) as resp:
                            if resp.status == 200:
                                # å…¼å®¹ï¼šå¯èƒ½ä¸æ˜¯ JSONï¼ˆæå°‘ï¼‰ï¼Œå…ˆ try jsonï¼Œå¤±è´¥å† text
                                try:
                                    data = await resp.json()
                                except Exception:
                                    txt = await resp.text()
                                    raise RuntimeError(f"OpenAI å“åº”éJSONï¼š{txt[:300]}")

                                # chat.completions ç»“æ„
                                try:
                                    return data["choices"][0]["message"]["content"]
                                except Exception:
                                    # å°è¯•å…¶å®ƒç»“æ„ï¼ˆå°½é‡ä¸ç ´ååŸåŠŸèƒ½ï¼‰
                                    if isinstance(data, dict) and isinstance(data.get("output_text"), str) and data["output_text"]:
                                        return data["output_text"]
                                    raise RuntimeError(f"OpenAI è¿”å›ç»“æ„æ— æ³•è§£æï¼š{list(data.keys())[:40]}")

                            # é 200ï¼šå°½å¯èƒ½æ‹¿åˆ°é”™è¯¯æ–‡æœ¬
                            err_text = ""
                            try:
                                err_text = await resp.text()
                            except Exception:
                                err_text = "<no body>"

                            # 429/503/504ï¼šé€šå¸¸è®¤ä¸ºèŠ‚ç‚¹æš‚ä¸å¯ç”¨ -> æœ¬è½®ç¦ç”¨
                            if resp.status in (429, 503, 504):
                                round_ctx.openai_banned.add(node_id)
                                log(f"ğŸš« [OpenAI] HTTP {resp.status} æœ¬è½®ç¦ç”¨èŠ‚ç‚¹ {remark} | {err_text[:200]}", "yellow")
                                await asyncio.sleep(min(10, 2 + attempt))
                                continue

                            # å…¶ä»– 4xx/5xxï¼šä¸ä¸€å®šè¦ç¦ç”¨ï¼Œä½†ä¸ºäº†ç¨³å¥å¯æŒ‰éœ€ç¦ç”¨
                            if resp.status >= 500:
                                round_ctx.openai_banned.add(node_id)
                                log(f"ğŸš« [OpenAI] HTTP {resp.status}ï¼ˆæœåŠ¡å™¨é”™è¯¯ï¼‰ç¦ç”¨èŠ‚ç‚¹ {remark} | {err_text[:200]}", "yellow")
                                await asyncio.sleep(min(10, 2 + attempt))
                                continue

                            # å…¶ä»–é”™è¯¯ï¼ˆå¦‚ 400/401/403ï¼‰ï¼šå¯èƒ½æ˜¯å‚æ•°æˆ– key é—®é¢˜ï¼Œç¦ç”¨é¿å…æ­»å¾ªç¯
                            if resp.status in (400, 401, 403):
                                round_ctx.openai_banned.add(node_id)
                                log(f"ğŸš« [OpenAI] HTTP {resp.status}ï¼ˆå¯èƒ½æ˜¯Key/å‚æ•°ï¼‰ç¦ç”¨èŠ‚ç‚¹ {remark} | {err_text[:200]}", "yellow")
                                await asyncio.sleep(min(8, 2 + attempt))
                                continue

                            # é»˜è®¤ï¼šä¿å®ˆé‡è¯•
                            last_err = RuntimeError(f"OpenAI HTTP {resp.status}: {err_text[:300]}")
                            log(f"âš ï¸ [OpenAI] HTTP {resp.status}ï¼š{err_text[:200]}", "yellow")
                            await asyncio.sleep(min(6, 1 + attempt))
                            continue

                    except aiohttp.ClientError as e:
                        last_err = e
                        round_ctx.openai_banned.add(node_id)
                        log(f"ğŸš« [OpenAI] ç½‘ç»œå¼‚å¸¸ï¼Œç¦ç”¨èŠ‚ç‚¹ {remark} | {e}", "yellow")
                        await asyncio.sleep(min(8, 2 + attempt))
                        continue
                    except asyncio.TimeoutError as e:
                        last_err = e
                        round_ctx.openai_banned.add(node_id)
                        log(f"ğŸš« [OpenAI] è¶…æ—¶ï¼Œç¦ç”¨èŠ‚ç‚¹ {remark}", "yellow")
                        await asyncio.sleep(min(10, 2 + attempt))
                        continue
                    except Exception as e:
                        last_err = e
                        # è‹¥æŠ¥é”™ç‰¹å¾åƒé™æµ/æ‹¥å¡ï¼Œä¹Ÿç¦ç”¨
                        msg = str(e).lower()
                        if "429" in msg or "rate" in msg or "overloaded" in msg:
                            round_ctx.openai_banned.add(node_id)
                        log(f"âš ï¸ [OpenAI] å¼‚å¸¸ï¼ˆå°†é‡è¯•/æ¢èŠ‚ç‚¹ï¼‰ï¼š{e}", "yellow")
                        await asyncio.sleep(min(6, 1 + attempt))
                        continue

        raise RuntimeError(f"OpenAI Protocol å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä»å¤±è´¥ï¼š{last_err}")

# ==========================================
# 6. ä¸»ç¨‹åº
# ==========================================
async def main():
    print("===========================================")
    print("   ğŸ¯ æ¨¡å—åŒ–å¢å¼ºå‹ï¼šç ”ç©¶ç¼ºå£æŒ–æ˜ç³»ç»Ÿ (ABCæ–¹æ¡ˆ)  ")
    print("===========================================")
    os.makedirs(DIR_OUTPUT_GAP, exist_ok=True)

    try:
        with open(CONFIG_FILENAME, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except Exception as e:
        log(f"âŒ æ— æ³•è¯»å–é…ç½® {CONFIG_FILENAME}: {e}", "red")
        return

    if not os.path.exists(PACK_FILE_PATH):
        log("âŒ æ‰¾ä¸åˆ°åº•å±‚ Pack æ–‡ä»¶", "red")
        return

    with open(PACK_FILE_PATH, 'r', encoding='utf-8') as f:
        pack_content = f.read()

    analysis_files = scan_analysis_files()
    if not analysis_files:
        log("âŒ æœªæ‰¾åˆ°ä»»ä½•æ¨¡å—åŒ–åˆ†ææŠ¥å‘Š (.md)", "red")
        return

    print("\nğŸ“‚ å‘ç°ä»¥ä¸‹å·²å®Œæˆçš„åˆ†ææŠ¥å‘Šï¼ˆæ¨¡å—åº“ï¼‰ï¼š")
    for idx, rf in enumerate(analysis_files, 1):
        print(f"   [{idx}] {rf['folder']} / {rf['filename']}")

    # æ”¯æŒå¤šé€‰çš„äº¤äº’é€»è¾‘ï¼ˆä¿æŒåŸåŠŸèƒ½ï¼‰
    while True:
        choice_str = input("\nğŸ‘‰ è¯·é€‰æ‹©è¦ä½œä¸ºåŸºåº•çš„æŠ¥å‘Š/ç»¼è¿° (è¾“å…¥åºå·ï¼Œå¤šé€‰è¯·ç”¨é€—å·åˆ†éš”ï¼Œå¦‚ 1,3,4): ").strip()
        if not choice_str:
            print("âš ï¸ å¿…é¡»è‡³å°‘é€‰æ‹©ä¸€ä»½æŠ¥å‘Šã€‚")
            continue
        try:
            choice_str = choice_str.replace('ï¼Œ', ',')
            indices = [int(x.strip()) for x in choice_str.split(',') if x.strip()]

            selected_files = []
            ok = True
            for idx in indices:
                if 1 <= idx <= len(analysis_files):
                    selected_files.append(analysis_files[idx - 1])
                else:
                    ok = False
                    break

            if ok and selected_files:
                break
            print("âš ï¸ åŒ…å«æ— æ•ˆçš„åºå·ï¼Œè¯·æ£€æŸ¥åé‡æ–°è¾“å…¥ã€‚")
        except ValueError:
            print("âš ï¸ æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥æ•°å­—åºå·ï¼Œå¤šé€‰è¯·ç”¨é€—å·åˆ†éš”ã€‚")

    # æ‹¼æ¥å¤šä¸ªæ¨¡å—æŠ¥å‘Šçš„å†…å®¹ï¼ˆä¿æŒåŸåŠŸèƒ½ï¼‰
    reports_content = ""
    report_names = []
    for sf in selected_files:
        with open(sf['path'], 'r', encoding='utf-8') as f:
            reports_content += f"\n\n============= ã€åŸºåº•æ¨¡å—ï¼š{sf['filename']}ã€‘ =============\n{f.read()}\n"
            report_names.append(sf['filename'])

    print("\n-------------------------------------------")
    topic = input("âœï¸  è¯·è¾“å…¥ã€ç›®æ ‡é€‰é¢˜ã€‘: ").strip()
    user_suggestion = input("âœï¸  è¯·è¾“å…¥ã€ä½ çš„æ ¸å¿ƒæ´å¯Ÿ/å»ºè®®ã€‘: ").strip()
    target_words = input("âœï¸  è¯·è¾“å…¥ã€æ¯ä¸ªæ–¹æ¡ˆçš„ç›®æ ‡å­—æ•°ã€‘: ").strip()

    final_prompt = PROMPT_TEMPLATE.format(topic=topic, user_suggestion=user_suggestion, target_words=target_words)
    combined_content = f"---åº•å±‚è¯æ® (PACK)---\n{pack_content}\n---æ·±åº¦åˆ†ææŠ¥å‘Šé›† (REPORTS)---\n{reports_content}"

    log(f"\nğŸš€ å·²æŒ‚è½½ {len(selected_files)} ä»½æ·±åº¦æ¨¡å—ï¼Œæ­£åœ¨æ¨æ¼” GAP æ–¹æ¡ˆ...", "cyan")

    stop_event = asyncio.Event()
    start_time = time.time()
    heartbeat_task = asyncio.create_task(show_heartbeat(start_time, stop_event))

    # è½®è¯¢æ± ä¸Šä¸‹æ–‡ï¼ˆä¿æŒâ€œå•ä»»åŠ¡ä¸€æ¬¡æ¨æ¼”â€ï¼Œè¿™é‡Œ round_id å›ºå®šä¸º 1ï¼‰
    round_ctx = RoundContext(round_id=1)
    client = AIClientRobust(config)
    client.begin_round(round_ctx)

    try:
        result = await client.call(combined_content, final_prompt, round_ctx)
        result = beautify_gap_md(result)

        safe_name = topic.replace("/", "_").replace("\\", "_")[:20]
        output_path = os.path.join(DIR_OUTPUT_GAP, f"Step6_{safe_name}_å¤šæ¨¡å—ç¼ºå£è®ºè¯.md")

        with open(output_path, "w", encoding="utf-8") as f:
            f.write(f"# æ¨¡å—åŒ–ç ”ç©¶ç¼ºå£ä¸‰æ–¹æ¡ˆè®ºè¯ï¼š{topic}\n\n")
            f.write(f"> **å·²æŒ‚è½½åŸºåº•æ¨¡å—**ï¼š\n")
            for name in report_names:
                f.write(f"> - {name}\n")
            f.write("\n")
            f.write(result)

        stop_event.set()
        await heartbeat_task
        log(f"ğŸ‰ ç ´é¢˜æˆåŠŸï¼å¤šæ¨¡å—æ•´åˆæ–¹æ¡ˆå·²ä¿å­˜è‡³: {output_path}", "green")

    except NoAvailableAPI as e:
        stop_event.set()
        await heartbeat_task
        log(f"âŒ æœ¬è½®æ‰€æœ‰ API ä¸å¯ç”¨ï¼š{e}", "red")
    except Exception as e:
        stop_event.set()
        await heartbeat_task
        log(f"âŒ ç”Ÿæˆå¤±è´¥: {e}", "red")
    finally:
        client.end_round()

if __name__ == "__main__":
    if sys.platform.startswith('win'):
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main())